# GRPO Training Configuration for Qwen 2.5 3B

data:
  dataset_name: "small_debate_dataset"  # "quality_questions"
  test_size: 0.16

# Model configuration
model:
  name: "Qwen/Qwen2.5-3B-Instruct"
  max_seq_length: 6144
  lora_rank: 64
  gpu_memory_utilization: 0.5

# Training configuration
training:
  learning_rate: 5e-6
  max_steps: 150
  batch_size: 1
  num_generations: 4
  beta: 0.1
  gradient_accumulation_steps: 2  # Increase to 4 for smoother training
  max_prompt_length: 2048
  max_completion_length: 4096
  max_grad_norm: 0.1

# Logging configuration
logging:
  report_to: "none"

# Reward configuration
reward:
  compare_against_reference: true
  max_completion_length: 1024
  length_reward_weight: 0.25
