# GRPO Training Configuration for Qwen 2.5 3B

data:
  dataset_name: "small_debate_dataset"  # "quality_questions"
  test_size: 0.16

# Model configuration
model:
  name: "Qwen/Qwen2.5-7B-Instruct"
  max_seq_length: 6144
  lora_rank: 64
  gpu_memory_utilization: 0.5

# Training configuration
training:
  learning_rate: 5e-6
  max_steps: 150
  batch_size: 64
  num_generations: 8
  beta: 0.1
  gradient_accumulation_steps: 2  # Increase to 4 for smoother training
  max_prompt_length: 2048
  max_completion_length: 4096
  max_grad_norm: 0.1

eval:
  batch_size: 128
  eval_strategy: "steps"
  eval_steps: 10

# Logging configuration
logging:
  report_to: "wandb"
  wandb_name: "grpo-small-debate"
  log_completions: true

# Reward configuration
reward:
  compare_against_reference: true
  max_completion_length: 2048  # NOTE: this is characters, not tokens
  length_reward_weight: 0.25
